---
title: "Blog Post 3"
subtitle: "Updates and Next Steps"
author: "Hannah, Rachel, Thao, Wenbo, Cuichen"
date: "2025-03-24"
date-modified: "2025-03-24"
draft: FALSE
---
# Our Progress

Over the past week, we made substantial progress in preparing our dataset for analysis. The original data came from the CalEnviroScreen 4.0 Excel file, which included multiple sheets—one containing pollution and environmental exposure data, and another with demographic indicators. We exported each sheet into separate CSV files, resulting in pollution_data.csv and demographic_data.csv. These were then read into R using read_csv() and merged using a left join on the "Census Tract" column to retain all pollution records while appending demographic information wherever available. After the merge, we removed several columns that were not directly relevant to our analysis, such as "Drinking Water", "Groundwater Threats", "Unemployment", and "Housing Burden", using a loop with select(-contains(...)). This approach allowed us to cleanly remove both the original and duplicated columns (e.g., .x, .y suffixes) introduced during merging.

We also addressed missing values by running colSums(is.na(cleaned_dataset)) to identify which variables had the most missing data. After reviewing the results—where "Low Birth Weight" had the highest number of NA values—we chose to drop all rows with missing values using drop_na() to ensure a clean dataset moving forward. 

Looking ahead, we plan to begin our exploratory data analysis by visualizing how pollution exposure correlates with demographic indicators such as race, age, and income. We are also beginning to consider additional data sources that could enrich our analysis—such as housing data, health outcome statistics, or climate-related variables—to explore deeper patterns of environmental injustice and vulnerability across California communities.

# Data for Equity

The beneficence principle applies where we have to be transparent about the limits of the data when processing and analyzing our data because we can only draw a limited number of conclusions using only the columns we have. Despite any wishes we may have to extend arguments to what causes the air pollution in some neighborhoods compared to others, our dataset only focuses on the pollution and health impacts without collecting data on how the neighborhoods may be developed infrastructurally to affect these outcomes. Regardless of what analytics we produce, we don’t have the data to make claims that the increased pollution is directly caused by any of the variables we have. In addition, we should also be clear about how any previous analysis done on the dataset informed our own analysis. 
	
Another principle that applies is justice. When conceiving the idea of the project, we should be clear on what the analysis would contribute to the communities it would affect. Although we may not be able to hold listening communities, we as analysts can take the responsibility to research more on the background of how air pollution can negatively impact vulnerable communities in California, and also understand the current state of what is being done to try and address the issue. For this dataset, there could be potential abuse or misuse if we try to conclude more about what causes the increased pollution, which would be not informed by the data we have available. Also, by understanding if communities are disproportionately impacted by air pollution, there is potential that the analysis could be used to support projects that push for developments in these neighborhoods that may not necessarily be wanted by the community.



## Looking into the Data + Cleaning
```{r}
#| echo: false
#| message: false
#| warning: false

library(tidyverse)
library(dplyr)
```

```{r}
data <- read_rds(here::here("dataset/cleaned_dataset.rds"))
pollution_data <- read_rds(here::here("dataset/pollution_data.rds"))
demographic_data <- read_rds(here::here("dataset/demographic_data.rds"))
```

There are 8035 unique census tracts, 58 California counties, and 785 approximate city/town/areas in the dataset.

```{r}
n_distinct(unique(pollution_data$`Census Tract`))
n_distinct(unique(pollution_data$`California County`))
n_distinct(unique(pollution_data$`Approximate Location`))
```

There were 3390 missing values in the pollution dataset and 516 missing values in the demographic dataset. However, none of the pollution data is missing.

```{r}
colSums(is.na(data))
```

This bar chart plots the number of missing values for the column CES 4.0 Score by California County. The CalEnviroScreen Score is the Pollution Score multiplied by Population Characteristics Score. Los Angles is the county with the most missing values. We can examine through the demographic data to understand what potential communities were not captured by this lack of data. The code to angle the x labels was sourced from [Substack](https://stackoverflow.com/questions/1330989/rotating-and-spacing-axis-labels-in-ggplot2)

```{r}
missing_counts <- pollution_data |>
  group_by(`California County`) |> 
  summarize(missing_count = sum(is.na(`CES 4.0 Score`))) |>
  filter(missing_count > 0) |>
  arrange(missing_count)


ggplot(missing_counts, aes(x = `California County`, y = `missing_count`, fill = `missing_count`)) +
  geom_bar(stat = "identity") +
  labs(title = "Missing Data Count by County",
       x = "California County",
       y = "Number of Missing Values") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

Will implement some sort of imputation to deal with the missing data. 