[
  {
    "objectID": "data.html#data-description",
    "href": "data.html#data-description",
    "title": "Data",
    "section": "Data Description",
    "text": "Data Description\nThe CalEnviroScreen data, available for download at “OEHHA’s website”, is compiled by the Office of Environmental Health Hazard Assessment (OEHHA) under the California Environmental Protection Agency (CalEPA). This dataset is designed to assess cumulative environmental burdens and population vulnerabilities across California’s communities. It includes indicators on pollution exposure, environmental effects, sensitive populations, and socioeconomic factors, allowing policymakers, researchers, and the public to identify areas most impacted by environmental hazards. The data was collected to support state efforts in environmental justice and resource allocation, particularly to assist in directing funding and policy initiatives to disadvantaged communities. By integrating environmental and demographic data, CalEnviroScreen provides a comprehensive tool for understanding disparities in environmental health risks across the state.\nThe data was collected to detect air pollution in small communities in California such as San Ysidro in San Diego. Since residents always complain that government air monitoring does not adequately measure air quality in their community. By collaborating with the San Ysidro community in San Diego, state and local government, and collecting data using low-cost technology, the San Ysidro Air Study group can give the rights to the general residents in San Ysidro for making decisions.\n\nWho put it together\nThe San Ysidro Air Study put the data together. But during the process of collecting data and selecting appropriate data, The San Ysidro Air Study group does corroborate with the local government, local groups(Casa Familiar), schools(University of Washington and San Diego State University), and The Community Steering Committee(including 12 volunteers from San Ysidro community)\n\n\nData Usage, Potential Similar Research, Analysis for Policy?\nThe CalEnviroScreen data has been used effectively in identifying the affected communities hence calling for policy action to direct cap-and-trade revenues to highly impacted areas, and also has been updated over the years to include more indicators and greater geographic specificity. This information is used by policymakers to allocate funds for environmental justice, guide regulatory enforcement, and support programs that target pollution control and public health improvements. The tool has also been applied to border regions under Assembly Bill 1059, which ensures pollution burdens within the context of environmental policies near the California-Mexico border.\nResearchers have used CalEnviroScreen to examine racial and socioeconomic disparities in environmental health risks. Cushing et al. (2015) found that pollution burdens disproportionately impact communities of color, particularly Hispanic and African American populations. Other studies, Alexeeff & Mataka (2014) and Meehan August et al. (2012), have explored methodological improvements and policy applications of the tool. Some of the key questions include how pollution exposure varies with race, how effective is the CalEnviroScreen and how can we improve it through additional indicators."
  },
  {
    "objectID": "data.html#data-files-and-description",
    "href": "data.html#data-files-and-description",
    "title": "Data",
    "section": "Data Files and Description",
    "text": "Data Files and Description\nThe original data was downloaded from CalEnviroScreen 4.0, which provides statewide data on environmental and demographic indicators at the census tract level. The data came in a single Excel file with multiple sheets. One sheet contained pollution and environmental exposure indicators, while another contained population and demographic characteristics. To prepare the data for analysis, we extracted each of these sheets and saved them as separate CSV files: pollution_data.csv and demographic_data.csv.\nThe pollution_data.csv file includes key variables such as Ozone, PM2.5, Diesel PM, and Traffic, along with their respective percentiles (e.g., “Ozone Pctl”, “PM2.5 Pctl”). These values quantify the level of environmental pollution affecting each census tract. It also includes summary indicators such as “Pollution Burden Score” and “CES 4.0 Score”, which are composite measures used by the state to assess environmental vulnerability.\nThe demographic_data.csv file contains population-level statistics, including Total Population, Children &lt; 10 years (%), and Elderly &gt; 64 years (%), as well as racial and ethnic breakdowns such as Hispanic (%), African American (%), and Asian American (%). These demographic variables allow for an assessment of how pollution levels intersect with age and race across regions.\nTo simplify the analysis, we focused on the most relevant environmental and demographic variables and removed columns related to less directly useful metrics like groundwater threats, education, and unemployment. Together, the cleaned and merged dataset allows us to explore the relationship between environmental burdens and community demographics in California.\n\nVariable description:\nEnvironmental Related statistics: like CES4.0 Score and PM 2.5 value, representing pollution score and levels.\nAge: Age of sample, ranging from children under 10 to elderly above 64\nLocation: California county that the census tract falls within\nRace: including races of samples in the research\nOther related statistics: Like poverty, education level, unemployment rate, Housing burden, Birth weight, potentially revealing relationships between those statistics and environmental levels. Offical Data Dictonary"
  },
  {
    "objectID": "data.html#data-loading-and-cleaning",
    "href": "data.html#data-loading-and-cleaning",
    "title": "Data",
    "section": "Data Loading and Cleaning",
    "text": "Data Loading and Cleaning\nMerging Pollution and Demographic Data\nFor this project, we worked with two datasets: pollution_data.csv and demographic_data.csv. Both datasets were read into R using the read_csv() function from the tidyverse package, and saved as .rds files using write_rds() for easier access later. The two datasets share some columns, including Total Population, California County, CES 4.0 Score, CES 4.0 Percentile, and CES 4.0 Percentile Range. So these columns were dropped from the pollution_data dataset before being merged with the demographic_data dataset. This was done using the following code:\n\npollution_data &lt;- pollution_data |&gt; \n                    select(-c('Total Population', 'California County', 'CES 4.0 Score', \n                              'CES 4.0 Percentile', 'CES 4.0 Percentile Range'))\n\nThe two datasets were then joined using a left join on the shared column “Census Tract” to ensure that all pollution records remained, even if corresponding demographic data was missing. This was done with the following line of code:\n\ncleaned_dataset &lt;- \n  left_join(pollution_data, demographic_data, by =\"Census Tract\")\n\nRemoving Columns\nAfter merging, we removed several columns that were not relevant to our analysis. The original dataset included data for both air and water pollution. However, since our project is focused on air pollution we have removed the columns relevant to water pollution. These included environmental and social indicators such as drinking water, lead, pesticides, unemployment, and housing burden. Because the merge process introduced suffixes like .x and .y to distinguish duplicate column names, we used a for loop combined with select(-contains(…)) to remove all columns containing those key patterns, regardless of suffix:\n\ncolumns_to_remove_patterns &lt;- c(\n\"Drinking Water\", \"Lead\", \"Pesticides\", \"Groundwater Threats\", \"Imp. Water Bodies\", \"Education\", \"Linguistic Isolation\",\"Poverty\", \"Unemployment\", \"Housing Burden\"\n)\n\nfor (pattern in columns_to_remove_patterns) {\n  cleaned_dataset &lt;- cleaned_dataset %&gt;%\n    select(-contains(pattern))\n}\n\nRemoving Missing Values\nWe then checked for missing values using colSums(is.na(cleaned_dataset)) and found that the variable with the most missing data was related to low birth weight. Despite this, we chose to remove all rows containing any missing values in the dataset using the drop_na() function from the tidyr package:\n\ncleaned_dataset &lt;- cleaned_dataset %&gt;%\n  drop_na()\n\nWriting the Transformation to Clenaed Dataset\nFinally, the cleaned dataset was saved using:\n\nwrite_rds(cleaned_dataset, file = here::here(\"dataset\", \"cleaned_dataset.rds\"))\n\nAll steps were carried out using packages from the tidyverse, including dplyr for data manipulation, readr for reading in the datasets, tidyr for handling missing values, and here for managing file paths. No additional R packages beyond those covered in class were used. A full record of these operations is provided in the script: clean_data.R."
  },
  {
    "objectID": "analysis.html",
    "href": "analysis.html",
    "title": "Analysis",
    "section": "",
    "text": "We describe here our detailed data analysis. This page will provide an overview of what questions you addressed, illustrations of relevant aspects of the data with tables and figures, and a statistical model that attempts to answer part of the question. You’ll also reflect on next steps and further analysis.\nThe audience for this page is someone like your class mates, so you can expect that they have some level of statistical and quantitative sophistication and understand ideas like linear and logistic regression, coefficients, confidence intervals, overfitting, etc.\nWhile the exact number of figures and tables will vary and depend on your analysis, you should target around 5 to 6. An overly long analysis could lead to losing points. If you want you can link back to your blog posts or create separate pages with more details.\nThe style of this paper should aim to be that of an academic paper. I don’t expect this to be of publication quality but you should keep that aim in mind. Avoid using “we” too frequently, for example “We also found that …”. Describe your methodology and your findings but don’t describe your whole process."
  },
  {
    "objectID": "analysis.html#rubric-on-this-page",
    "href": "analysis.html#rubric-on-this-page",
    "title": "Analysis",
    "section": "Rubric: On this page",
    "text": "Rubric: On this page\nYou will\n\nIntroduce what motivates your Data Analysis (DA)\n\nWhich variables and relationships are you most interested in?\nWhat questions are you interested in answering?\nProvide context for the rest of the page. This will include figures/tables that illustrate aspects of the data of your question.\n\nModeling and Inference\n\nThe page will include some kind of formal statistical model. This could be a linear regression, logistic regression, or another modeling framework.\nExplain the ideas and techniques you used to choose the predictors for your model. (Think about including interaction terms and other transformations of your variables.)\nDescribe the results of your modelling and make sure to give a sense of the uncertainty in your estimates and conclusions.\n\nExplain the flaws and limitations of your analysis\n\nAre there some assumptions that you needed to make that might not hold? Is there other data that would help to answer your questions?\n\nClarity Figures\n\nAre your figures/tables/results easy to read, informative, without problems like overplotting, hard-to-read labels, etc?\nEach figure should provide a key insight. Too many figures or other data summaries can detract from this. (While not a hard limit, around 5 total figures is probably a good target.)\nDefault lm output and plots are typically not acceptable.\n\nClarity of Explanations\n\nHow well do you explain each figure/result?\nDo you provide interpretations that suggest further analysis or explanations for observed phenomenon?\n\nOrganization and cleanliness.\n\nMake sure to remove excessive warnings, hide all code, organize with sections or multiple pages, use bullets, etc.\nThis page should be self-contained, i.e. provide a description of the relevant data."
  },
  {
    "objectID": "analysis.html#introduction",
    "href": "analysis.html#introduction",
    "title": "Analysis",
    "section": "Introduction",
    "text": "Introduction\n\nMotivation\nThe analysis aims to investigate the relationship between demographic factors (e.g., race, ethnicity) and pollution burden in California’s census tracts. Understanding these relationships is essential for targeting environmental policies that mitigate pollution’s impact on vulnerable communities. By examining how demographic characteristics influence the pollution burden, we can highlight areas that may need focused intervention to reduce environmental inequities.\n\n\nKey Questions\nWe are particularly interested in understanding how the proportion of Hispanic, African American, and Asian American populations within census tracts correlates with the pollution burden score. Specifically, we seek to answer the following questions:\n\nHow does the percentage of each racial/ethnic group (Hispanic, African American, Asian American, etc.) correlate with the pollution burden score in California census tracts?\nAre certain demographic groups more likely to live in high-pollution areas?\n\nTo explore these questions, we present visualizations and statistical models that analyze these relationships. The following figures and tables will provide insights into the distribution of demographic groups, the extent of pollution in different counties, and the impact of racial composition on pollution levels."
  },
  {
    "objectID": "analysis.html#data-overview-and-inital-exploration",
    "href": "analysis.html#data-overview-and-inital-exploration",
    "title": "Analysis",
    "section": "Data Overview and Inital Exploration",
    "text": "Data Overview and Inital Exploration\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(dplyr)\ndata &lt;- read_rds(here::here(\"dataset/cleaned_dataset.rds\"))\npollution_data &lt;- read_rds(here::here(\"dataset/pollution_data.rds\"))\ndemographic_data &lt;- read_rds(here::here(\"dataset/demographic_data.rds\"))\n\nThere are 8035 unique census tracts, 58 California counties, and 785 approximate city/town/areas in the dataset.\n\nn_distinct(unique(pollution_data$`Census Tract`))\n\n[1] 8035\n\nn_distinct(unique(pollution_data$`California County`))\n\n[1] 58\n\nn_distinct(unique(pollution_data$`Approximate Location`))\n\n[1] 785\n\n\nThere were 3390 missing values in the pollution dataset and 516 missing values in the demographic dataset. However, none of the pollution data is missing.\n\ncolSums(is.na(pollution_data))\n\n               Census Tract            Total Population \n                          0                           0 \n          California County                         ZIP \n                          0                           0 \n       Approximate Location                   Longitude \n                          0                           0 \n                   Latitude               CES 4.0 Score \n                          0                         103 \n         CES 4.0 Percentile    CES 4.0 Percentile Range \n                        103                         103 \n                      Ozone                  Ozone Pctl \n                          0                           0 \n                      PM2.5                  PM2.5 Pctl \n                          0                           0 \n                  Diesel PM              Diesel PM Pctl \n                          0                           0 \n             Drinking Water         Drinking Water Pctl \n                         28                          28 \n                       Lead                   Lead Pctl \n                         96                          96 \n                 Pesticides             Pesticides Pctl \n                          0                           0 \n               Tox. Release           Tox. Release Pctl \n                          0                           0 \n                    Traffic                Traffic Pctl \n                         35                          35 \n              Cleanup Sites          Cleanup Sites Pctl \n                          0                           0 \n        Groundwater Threats    Groundwater Threats Pctl \n                          0                           0 \n                 Haz. Waste             Haz. Waste Pctl \n                          0                           0 \n          Imp. Water Bodies      Imp. Water Bodies Pctl \n                          0                           0 \n                Solid Waste            Solid Waste Pctl \n                          0                           0 \n           Pollution Burden      Pollution Burden Score \n                          0                           0 \n      Pollution Burden Pctl                      Asthma \n                          0                          11 \n                Asthma Pctl            Low Birth Weight \n                         11                         227 \n      Low Birth Weight Pctl      Cardiovascular Disease \n                        227                          11 \nCardiovascular Disease Pctl                   Education \n                         11                         103 \n             Education Pctl        Linguistic Isolation \n                        103                         320 \n  Linguistic Isolation Pctl                     Poverty \n                        320                          75 \n               Poverty Pctl                Unemployment \n                         75                         335 \n          Unemployment Pctl              Housing Burden \n                        335                         145 \n        Housing Burden Pctl                  Pop. Char. \n                        145                         103 \n           Pop. Char. Score             Pop. Char. Pctl \n                        103                         103 \n\n\nThis bar chart plots the number of missing values for the column CES 4.0 Score by California County. The CalEnviroScreen Score is the Pollution Score multiplied by Population Characteristics Score. Los Angles is the county with the most missing values. We can examine through the demographic data to understand what potential communities were not captured by this lack of data. The code to angle the x labels was sourced from Substack\n\nmissing_counts &lt;- pollution_data |&gt;\n  group_by(`California County`) |&gt; \n  summarize(missing_count = sum(is.na(`CES 4.0 Score`))) |&gt;\n  filter(missing_count &gt; 0) |&gt;\n  arrange(missing_count)\n\n\nggplot(missing_counts, aes(x = `California County`, y = `missing_count`, fill = `missing_count`)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Missing Data Count by County\",\n       x = \"California County\",\n       y = \"Number of Missing Values\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))"
  },
  {
    "objectID": "analysis.html#data-visualization",
    "href": "analysis.html#data-visualization",
    "title": "Analysis",
    "section": "Data Visualization",
    "text": "Data Visualization\nFor each census tract, races that are non-white tend to have smaller population percentages that are less than 25% of the census tract.\n\ndemo_long &lt;- demographic_data |&gt;\n  pivot_longer(cols = c(`Hispanic (%)`, `White (%)`, `African American (%)`, `Native American (%)`,`Asian American (%)`,`Other/Multiple (%)`),\n               names_to = \"Race\",\n               values_to = \"Percentage\")\n\nggplot(demo_long, aes(x = Percentage)) +\n  geom_histogram(binwidth = 5) + \n  facet_wrap(~Race, scales = \"free_y\") + \n  labs(title = \"Distribution of Race Percentages\",\n       x = \"Percentage\",\n       y = \"Frequency\")\n\nWarning: Removed 138 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n\nPollution vs. Race\n\nggplot(data, aes(x = `Hispanic (%)`, y = `Pollution Burden Score`)) +\n  geom_point(alpha = 0.3, color = \"darkgreen\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(title = \"Pollution Burden vs. Hispanic\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nTop 10 Most Polluted Counties\n\ndata %&gt;%\n  group_by(`California County`) %&gt;%\n  summarise(mean_pollution = mean(`Pollution Burden Score`, na.rm = TRUE)) %&gt;%\n  top_n(10, mean_pollution) %&gt;%\n  ggplot(aes(x = reorder(`California County`, mean_pollution), y = mean_pollution)) +\n  geom_col(fill = \"steelblue\") +\n  coord_flip() +\n  labs(title = \"Top 10 Most Polluted Counties\", x = NULL, y = \"Avg. Pollution Score\")\n\n\n\n\n\n\n\n\n\ntop_polluted_counties &lt;- data %&gt;%\n  group_by(`California County`) %&gt;%\n  summarise(mean_pollution = mean(`Pollution Burden Score`, na.rm = TRUE)) %&gt;%\n  top_n(10, mean_pollution) \n\nggplot(top_polluted_counties, aes(x = reorder(`California County`, mean_pollution), y = mean_pollution, fill = mean_pollution)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() +\n  labs(title = \"Top 10 Most Polluted Counties in California\",\n       x = \"County\",\n       y = \"Average Pollution Score\") +\n  scale_fill_viridis_c() +\n  theme_minimal()\n\n\n\n\n\n\n\n\nFrom Chat\n\nmissing_counts &lt;- data %&gt;%\n  summarise(across(everything(), ~sum(is.na(.)))) %&gt;%\n  gather(key = \"variable\", value = \"missing_count\")\n\nggplot(missing_counts, aes(x = reorder(variable, missing_count), y = missing_count, fill = missing_count)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Missing Data in Variables\",\n       x = \"Variable\",\n       y = \"Number of Missing Values\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +\n  scale_fill_viridis_c()\n\n\n\n\n\n\n\n\n\ndemo_long &lt;- data %&gt;%\n  pivot_longer(cols = c(`Hispanic (%)`, `White (%)`, `African American (%)`, `Native American (%)`, \n                        `Children &lt; 10 years (%)`, `Pop 10-64 years (%)`, `Elderly &gt; 64 years (%)`),\n               names_to = \"Demographic\", values_to = \"Percentage\")\n\n\nggplot(demo_long, aes(x = Demographic, y = Percentage, fill = Demographic)) +\n  geom_boxplot() +\n  labs(title = \"Boxplot of Demographic Percentages Across Census Tracts\",\n       x = \"Demographic Group\",\n       y = \"Percentage of Population\") +\n  theme_minimal() +\n  coord_flip() \n\n\n\n\n\n\n\n\n\nggplot(data, aes(x = `Pollution Burden Score`)) +\n  geom_histogram(binwidth = 1, fill = \"steelblue\", color = \"black\", alpha = 0.7) +\n  labs(title = \"Distribution of Pollution Burden Scores\",\n       x = \"Pollution Burden Score\",\n       y = \"Frequency\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nggplot(data, aes(x = `Pollution Burden Score`, y = `Asthma`)) +\n  geom_point(alpha = 0.3, color = \"orange\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(title = \"Pollution Burden vs. Asthma Rate\",\n       x = \"Pollution Burden Score\",\n       y = \"Asthma Rate\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nlibrary(corrplot)\n\ncorrplot 0.95 loaded\n\nexclude_vars &lt;- c(\"CES 4.0 Score.x\", \"CES 4.0 Percentile.x\", \"CES 4.0 Percentile Range.x\", \n                  \"CES 4.0 Score.y\", \"CES 4.0 Percentile.y\", \"Pollution Burden Pctl\")\n\nnumeric_data &lt;- data %&gt;%\n  select_if(is.numeric) %&gt;%\n  select(-one_of(exclude_vars))\n\nWarning: Unknown columns: `CES 4.0 Score.x`, `CES 4.0 Percentile.x`, `CES 4.0\nPercentile Range.x`, `CES 4.0 Score.y`, `CES 4.0 Percentile.y`\n\ncorrelation_matrix_filtered &lt;- cor(numeric_data, use = \"complete.obs\")\n\npollution_burden_corr &lt;- correlation_matrix_filtered[\"Pollution Burden Score\",]\n\nsorted_corr &lt;- sort(abs(pollution_burden_corr), decreasing = TRUE)\n\ntop_10_variables &lt;- names(sorted_corr[2:11])\n\ntop_corr_matrix &lt;- correlation_matrix_filtered[top_10_variables, top_10_variables]\n\ncorrplot(top_corr_matrix, \n         method = \"color\", \n         type = \"upper\", \n         title = \"Top 10 Variables Correlated with Pollution Burden Score (Excluding CES 4.0 Score)\", \n         tl.cex = 0.7, \n         tl.srt = 45, # Rotate text labels for readability\n         mar = c(0, 0, 3, 0), # Increase space around the plot\n         number.cex = 0.7) # Adjust number size\n\n\n\n\n\n\n\n\n\nModeling and Inference\n\nmodel &lt;- lm(`Pollution Burden Score` ~ `Hispanic (%)` + \n            `African American (%)` + `Asian American (%)` + \n            `Native American (%)` + `Other/Multiple (%)`,\n          data = data)\n\n# Get model summary with confidence intervals\nsummary(model)\n\n\nCall:\nlm(formula = `Pollution Burden Score` ~ `Hispanic (%)` + `African American (%)` + \n    `Asian American (%)` + `Native American (%)` + `Other/Multiple (%)`, \n    data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.0139 -0.9196 -0.0259  0.9106  4.7058 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)             3.9215202  0.0546831  71.714  &lt; 2e-16 ***\n`Hispanic (%)`          0.0291672  0.0007253  40.213  &lt; 2e-16 ***\n`African American (%)`  0.0182319  0.0017846  10.216  &lt; 2e-16 ***\n`Asian American (%)`    0.0117560  0.0010380  11.326  &lt; 2e-16 ***\n`Native American (%)`  -0.0461417  0.0152146  -3.033  0.00243 ** \n`Other/Multiple (%)`   -0.0187340  0.0074291  -2.522  0.01170 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.33 on 7779 degrees of freedom\nMultiple R-squared:  0.2539,    Adjusted R-squared:  0.2534 \nF-statistic: 529.3 on 5 and 7779 DF,  p-value: &lt; 2.2e-16\n\nconfint(model)\n\n                              2.5 %       97.5 %\n(Intercept)             3.814326659  4.028713833\n`Hispanic (%)`          0.027745431  0.030589041\n`African American (%)`  0.014733638  0.021730196\n`Asian American (%)`    0.009721265  0.013790767\n`Native American (%)`  -0.075966475 -0.016316952\n`Other/Multiple (%)`   -0.033297099 -0.004170951\n\n\n\ncoef_plot &lt;- ggplot(data.frame(\n  term = c(\"Hispanic\", \"African American\", \"Asian American\", \n           \"Native American\", \"Other/Multiple\"),\n  estimate = c(0.030, 0.018, 0.013, 0.006, -0.016),\n  ci_lower = c(0.029, 0.015, 0.011, -0.007, -0.030),\n  ci_upper = c(0.031, 0.022, 0.015, 0.020, -0.002)\n), aes(x = estimate, y = term)) +\n  geom_vline(xintercept = 0, linetype = \"dashed\", color = \"gray50\") +\n  geom_point(size = 2) +\n  geom_errorbarh(aes(xmin = ci_lower, xmax = ci_upper), height = 0.2) +\n  labs(title = \"Demographic Predictors of Pollution Burden\",\n       subtitle = \"Coefficient estimates with 95% confidence intervals\",\n       x = \"Effect Size (Change in Pollution Score per 1% Increase)\",\n       y = \"Demographic Group\") +\n  theme_minimal()\n\nprint(coef_plot)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MA [46]15 Final Project",
    "section": "",
    "text": "Final Project due May 5, 2024 at 11:59pm.\nThis comes from the index.qmd file.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post 7\n\n\n\n\n\n\n\n\n\n\n\nApr 22, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post 6\n\n\n\n\n\n\n\n\n\n\n\nApr 14, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nblog post 5\n\n\n\n\n\n\n\n\n\n\n\nApr 7, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post 4\n\n\n\n\n\n\n\n\n\n\n\nMar 31, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post 3\n\n\nUpdates and Next Steps\n\n\n\n\n\n\n\n\nMar 24, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post 2\n\n\n\n\n\n\n\n\n\n\n\nMar 17, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post 1\n\n\n\n\n\nblog post 1 \n\n\n\n\n\nMar 2, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nGeneral Tips\n\n\n\n\n\nSome small but important tips to follow. \n\n\n\n\n\nOct 4, 2024\n\n\nDaniel Sussman\n\n\n\n\n\n\n\n\n\n\n\n\nExamples\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 26, 2024\n\n\nDaniel Sussman\n\n\n\n\n\n\n\n\n\n\n\n\nGetting started\n\n\n\n\n\n\n\n\nDirections to set up your website and create your first post. \n\n\n\n\n\nFeb 23, 2024\n\n\nDaniel Sussman\n\n\n\n\n\n\n\n\n\n\n\n\nFirst Team Meeting\n\n\n\n\n\n\n\n\nThis post details the steps you’ll take for your first team meeting. \n\n\n\n\n\nFeb 21, 2024\n\n\nDaniel Sussman\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2023-12-20-examples/examples.html",
    "href": "posts/2023-12-20-examples/examples.html",
    "title": "Examples",
    "section": "",
    "text": "Here are some examples of changing the size of a figure.\n\nplot(1:10)\n\n\n\n\n\n\n\n\n\nplot(1:10)\n\n\n\n\n\n\n\n\nWe can also specify column: screen and out-width: 100% so that the figure will fill the screen. plot in the svg vector graphics file format.\n\nlibrary(ggplot2)\nggplot(pressure, aes(x = temperature, y = pressure)) + geom_point()"
  },
  {
    "objectID": "posts/2023-12-20-examples/examples.html#figure-sizing",
    "href": "posts/2023-12-20-examples/examples.html#figure-sizing",
    "title": "Examples",
    "section": "",
    "text": "Here are some examples of changing the size of a figure.\n\nplot(1:10)\n\n\n\n\n\n\n\n\n\nplot(1:10)\n\n\n\n\n\n\n\n\nWe can also specify column: screen and out-width: 100% so that the figure will fill the screen. plot in the svg vector graphics file format.\n\nlibrary(ggplot2)\nggplot(pressure, aes(x = temperature, y = pressure)) + geom_point()"
  },
  {
    "objectID": "posts/2025-03-02-blog-post-1/blog-post-1.html",
    "href": "posts/2025-03-02-blog-post-1/blog-post-1.html",
    "title": "Blog Post 1",
    "section": "",
    "text": "Dataset 1\nLink to Data Description: https://data.cityofnewyork.us/City-Government/Evictions/6z8x-wfk4/about_data\nThe New York City Department of Investigation updates a dataset daily on pending, scheduled and executed evictions within the five boroughs from the year 2017 to the present. The data is compiled from the majority of New York City Marshals, who are independent public officials. The dataset has 104,860 rows that each represent a pending, scheduled, or executed eviction. It also has 20 columns, which iIncludes attributes, such as Court Index Number, Docket Number, Eviction Address, Apartment Number, Executed Date, Marshal First Name, Marshal Last Name, Residential or Commercial (property type), Borough, Zip Code and Scheduled Status (Pending/Scheduled). We will be able to download the data as a csv file from the NYC Open Data website and potentially explore questions, such as the relationship between NYC housing eviction rate and neighborhood, what neighborhoods are more often subject to evictions, and if there any patterns between the ethnic makeup of the neighborhood with the number of evictions. It may be a challenge to make connections to racial disparities because the dataset itself does not have racial demographic data and this would have to be sourced based on the zip codes of where the evictions are taking place.\n\n\nDataset 2\nLink to Data Description: https://drive.google.com/file/d/1QRubjBCrkqe61iDkxFg7P_Lc1SkR2PhL/view?usp=sharing\nThe California Office of Environmental Health Hazard Assessment (OEHHA) developed a dataset with 8,035 census tracts and 58 columns to identify communities most burdened by pollution and vulnerable populations. It integrates environmental indicators (e.g., air pollution, drinking water contamination) and population characteristics (e.g., poverty, asthma rates, linguistic isolation) to guide environmental justice policies. Key research questions include whether communities with higher racial/ethnic minority populations face greater air pollution exposure and if specific racial/ethnic groups experience multiple pollution burdens disproportionately. A potential challenge is that the dataset only covers California, limiting generalizability to the U.S. Additionally, the racial/ethnic data is in a separate sheet, requiring a join on the Census Tract column for analysis. The data has been successfully loaded and is ready for cleaning.\n\n\nDataset 3\nLink to Data Description: https://catalog.data.gov/dataset/rates-and-trends-in-hypertension-related-cardiovascular-disease-mortality-among-us-ad-2000-2fdf2\nThis dataset documents rates and trends in local hypertension-related cardiovascular disease (CVD) death rates. The dataset contains 1103872 rows and 24 columns, including information on county (or county equivalent) estimates of hypertension-related CVD death rates in 2000-2019 and trends during two intervals (2000-2010, 2010-2019) by age group (ages 35–64 years, ages 65 years and older), race/ethnicity (non-Hispanic American Indian/Alaska Native, non-Hispanic Asian/Pacific Islander, non-Hispanic Black, Hispanic, non-Hispanic White), and sex (female, male). The rates and trends were estimated using a Bayesian spatiotemporal model and a smoothed over space, time, and demographic group. Rates are age-standardized in 10-year age groups using the 2010 US population."
  },
  {
    "objectID": "posts/2024-10-04-general-tips/general-tips.html",
    "href": "posts/2024-10-04-general-tips/general-tips.html",
    "title": "General Tips",
    "section": "",
    "text": "Use the tidyverse!\nYou don’t have to tell me what kind of chart something is. For example, the below is not a useful start to a sentence.\n\n\nThe graph presents a horizontal bar chart …\n\n\nEach page should be largely standalone.\nSometimes small tables or even inline numbers are better than a figure.\nRedundant colors (e.g. bar charts where each bar is a different color that doesn’t signify anything) often don’t help.\nProvide some details on how much data was removed in your cleaning process.\nUse the tidyverse!\nImagine I’m an impatient boss. Show me only what is important and relevant.\nCleaning must be entirely in R\nDon’t say things like, well if only everyone did like so and so than everything would be better. There are many things hiding behind the data that would go to explain things. This is an example of a bad conclusion.\n\n\nThe world could benefit form modeling its education systems after Europe’s.\n\nIt is fine to talk about how the European system is better according to certain metrics, but don’t assume that can easily translate to other regions.\n\nDon’t talk about your “journey”. The blog posts tell the story of your journey. The main pages should focus on the data and your findings.\n\n\nUse the tidyverse!\nNo but seriously, when asking ChatGPT to do your project for you, make sure to tell it to use the tidyverse, not base R."
  },
  {
    "objectID": "posts/2025-03-17-blog-post-2/blog-post-2.html",
    "href": "posts/2025-03-17-blog-post-2/blog-post-2.html",
    "title": "Blog Post 2",
    "section": "",
    "text": "Our Progress\nOur team has officially decided to move forward with our project on disparities in air pollution exposure among racial and ethnic groups. We have made some progress on the Data page, working on the data description section. Our group has decided to split the parts of the rubric to complete the Data page. We are first working on each section of the page on a Google doc and will combine all of our work onto the qmd file later on.\nAs for the data, we are focused on integrating racial demographic information by joining our two datasets in the “Census Tract” column. This step allows us to analyze air pollution exposure in the context of racial and ethnic composition across different geographic areas. Currently, our data is separated into two files. One with information on air pollution and the other with demographic information. Once this integration is complete, our next steps will involve exploring and cleaning the data to address missing values, potential inconsistencies, and outliers. This will ensure the dataset is structured properly for in-depth analysis. In the coming weeks, we plan to conduct exploratory data analysis (EDA), visualizing trends and disparities to gain initial insights before diving into more advanced statistical and spatial analysis."
  },
  {
    "objectID": "posts/2023-10-13-first-team-meeting/first-team-meeting.html",
    "href": "posts/2023-10-13-first-team-meeting/first-team-meeting.html",
    "title": "First Team Meeting",
    "section": "",
    "text": "These are the steps that you will take today to get started on your project. Today, you will just be brainstorming, and then next week, you’ll get started on the main aspects of the project.\n\nStart by introducing yourselves to each other. I also recommend creating a private channel on Microsoft Teams with all your team members. This will be a place that you can communicate and share ideas, code, problems, etc.\nDiscuss what aspects of the project each of you are more or less excited about. These include\n\nCollecting, cleaning, and munging data ,\nStatistical Modeling,\nVisualization,\nWriting about analyses, and\nManaging and reviewing team work.\n\nBased on this, discuss where you feel your strengths and weaknesses might be.\nNext, start brainstorming questions you hope to answer as part of this project. This question should in some way be addressing issues around racial disparities. The questions you come up with should be at the level of the question we started with when exploring the HMDA data. (“Are there differences in the ease of securing a loan based on the race of the applicant?”) You’ll revise your questions a lot over the course of the project. Come up with a few questions that your group might be interested in exploring.\nBased on these questions, start looking around for data that might help you analyze this. If you are looking at U.S. based data, data.gov is a good source and if you are looking internationally, I recommend checking out the World Bank. Also, try Googling for data. Include “data set” or “dataset” in your query. You might even include “CSV” or some other format. Using “data” by itself in your query often doesn’t work too well. Spend some time searching for data and try to come up with at least three possible data sets. (For your first blog post, you’ll write short proposals about each of them that I’ll give feedback on.)\nCome up with a team name. Next week, I’ll provide the Github Classroom assignment that will be where you work on your final project and you’ll have to have your team name finalized by then. Your project will be hosted online at the website with a URL like sussmanbu.github.io/ma4615-fa23-final-project-TEAMNAME.\n\nNext time, you’ll get your final project website set up and write your first blog post."
  },
  {
    "objectID": "posts/2023-10-15-getting-started/getting-started.html",
    "href": "posts/2023-10-15-getting-started/getting-started.html",
    "title": "Getting started",
    "section": "",
    "text": "Below, the items marked with [[OP]] should only be done by one person on the team.\n\nTo get started\n\n[[OP]] One person from the team should click the Github Classroom link on Teams.\n[[OP]] That person types in the group name for their group.\nThe rest of the team now clicks the Github Classroom link and selects their team from the dropdown list.\nFinally, each of you can clone the repository to your laptop like a normal assignment.\n\n\n\nSetting up the site\n\n[[OP]] Open the terminal and run quarto publish gh-pages.\n[[OP]] Select Yes to the prompt:  ? Publish site to https://sussmanbu.github.io/ma4615-fa23-final-project-TEAMNAME/ using gh-pages? (Y/n)\n[[OP]] Wait for the process to finish.\nOnce it is done, you can go to the URL it asked you about to see your site.\n\nNote: This is the process you will use every time you want to update your published site. Make sure to always follow the steps below for rendering, previewing, and committing your changes before doing these publish steps. Anyone can publish in the future.\n\n\nCustomize your site\n\n[[OP]] Open the _quarto.yml file and update the title to include your team name.\n[[OP]] Go to the about.qmd and remove the TF’s and professor’s names.\nadd your own along with a short introduction and a link to your Github user page.\n[[OP]] Render the site.\n[[OP]] Check and make sure you didn’t get any errors.\n[[OP]] Commit your changes and push.\n[[OP]] Repeat the steps under Setting up your site.\n\nOnce one person is done with this, each teammate in the group can, in turn, repeat steps 3-7. Before doing so, make sure to pull the changes from teammates before starting to make new changes. (We’ll talk soon about ways to organize your work and resolve conflicts.)\n\n\nStart your first post\n\nTo start your first post first, run remotes::install_github(\"sussmanbu/quartopost\") in your Console.\n[[OP]] Run quartopost::quartopost() (or click Addins-&gt;Create Quarto Post, or use C-Shift-P, type “Create Quarto” and press enter to run the command).\n\nNow you can start working on your post. You’ll want to render your post to see what it will look like on the site.\n\nEvery time you want to make a new post, you can repeat step 2 above.\nWhen you want to publish your progress, follow steps 4-7 from Customize your site.\n\nFinally, make sure to read through everything on this site which has the directions and rubric for the final project."
  },
  {
    "objectID": "posts/2025-04-22-blog-post-7/blog-post-7.html",
    "href": "posts/2025-04-22-blog-post-7/blog-post-7.html",
    "title": "Blog Post 7",
    "section": "",
    "text": "This week, we are in the process of developing an interactive Shiny app for our final project. This users to explore pollution burden scores by selecting a county and a demographic group. It dynamically visualizes how the percentage of a specific group relates to pollution levels within that county.\nOur interactive supports both broad trend exploration of the data. It includes user input for customization and a clean layout for clarity. We’re planning to add brief instructions to guide users through the visualizations as well as zoom-in analysis.\nWe’re also exploring a new feature that compares a selected county’s average pollution burden score to the statewide average. This would make the tool more personal, helping California residents understand how their local environment compares to the rest of the state.\nNext steps include:\n\nImplementing the county vs. state average comparison.\nImproving the app’s visual design.\nHighlighting counties with especially high pollution burdens.\n\nHere is a interactive that is in the works:\n#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 500\n \nlibrary(shiny)\nlibrary(tidyverse)\n\n \ndata &lt;- read_rds(\"https://raw.githubusercontent.com/sussmanbu/ma4615-sp25-final-project-data-warriors/main/dataset_for_shiny/county_demographic.rds\")\n\nui &lt;- fluidPage(\n  titlePanel(\"Explore Pollution Burden by County and Demographics\"),\n  sidebarLayout(\n    sidebarPanel(\n      selectInput(\"county\", \"Select a County:\",\n                  choices = sort(unique(data$`California County`))),\n      selectInput(\"demographic\", \"Select Demographic Group:\",\n                  choices = c(\"Hispanic (%)\", \"White (%)\", \"African American(%)\", \"Asian American (%)\", \"Native American (%)\", \"Other/Multiple (%)\"))\n    ),\n    mainPanel(\n      plotOutput(\"demoPlot\")\n    )\n  )\n)\n \nserver &lt;- function(input, output) {\n  output$demoPlot &lt;- renderPlot({\n    plot_data &lt;- data %&gt;% filter(`California County` == input$county)\n \n    ggplot(\n      plot_data,\n      aes_string(\n        x = paste0(\"`\", input$demographic, \"`\"),\n        y = \"`Pollution Burden Score`\"\n      )\n    ) +\n      geom_point(alpha = 0.5, color = \"darkblue\") +\n      geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n      labs(\n        title = paste(\"Pollution vs.\", input$demographic, \"in\", input$county),\n        x = input$demographic,\n        y = \"Pollution Burden Score\"\n      ) +\n      theme_minimal()\n  })\n}\n \n \nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "posts/2025-04-07-blog-post-5/blog-post-5.html",
    "href": "posts/2025-04-07-blog-post-5/blog-post-5.html",
    "title": "blog post 5",
    "section": "",
    "text": "Our CalEnviroScreen data came in a single Excel file with multiple sheets. One sheet contained pollution and environmental exposure indicators and another sheet contained population and demographic characteristics. We joined these two datasets to inform our research question of understanding which demographics may be disproportionately impacted by environmental health risks. Both datasets contain a column named “Census Tract”, which allows us to do a left join on the pollution and environmental exposure indicators to add demographic information about each census tract. We used a left join to preserve all pollution data records while adding any available demographic data. The data joining process didn’t have too many challenges, but in order to ensure that columns were not duplicated between the pollution dataset and the demographic dataset, we had to drop the columns ‘Total Population’, ‘California County’, ‘CES 4.0 Score’, ‘CES 4.0 Percentile’, and ‘CES 4.0 Percentile Range’ from the demographic data first.\nOur initial findings suggest there’s a relationship between pollution burden and the proportion of a census tract that is Hispanic, which is from Blog post 4. However, in our next steps we also plan to explore the relationship between pollution scores and more columns within our dataset outside of demographics, such as poverty percentile, unemployment percentile, and housing percentile. This week we spent more time understanding what rows we missed out on by dropping any rows with nulls because initially when we were cleaning our dataset we removed any nulls. In our exploration we found that while the pollution data didn’t have any nulls in the pollution burden columns, the nulls were largely concentrated in many of the columns we planned to look into related to other characteristics including Housing Burden Pctl, Poverty Pctl, and Unemployment Pctl as seen in the code below. The nulls are also mainly concentrated in Los Angeles, Riverside, and Orange county. Moving forward we’d have to do more exploratory data analysis to understand the demographic communities we’d be missing out on by dropping these rows as a next step.\n\nsuppressPackageStartupMessages(library(dplyr))\nsuppressPackageStartupMessages(library(tidyverse))\npollution_data &lt;- read_rds(here::here(\"dataset/pollution_data.rds\"))\ndemographic_data &lt;- read_rds(here::here(\"dataset/demographic_data.rds\"))\n\ncolSums(is.na(pollution_data))\n\n               Census Tract            Total Population \n                          0                           0 \n          California County                         ZIP \n                          0                           0 \n       Approximate Location                   Longitude \n                          0                           0 \n                   Latitude               CES 4.0 Score \n                          0                         103 \n         CES 4.0 Percentile    CES 4.0 Percentile Range \n                        103                         103 \n                      Ozone                  Ozone Pctl \n                          0                           0 \n                      PM2.5                  PM2.5 Pctl \n                          0                           0 \n                  Diesel PM              Diesel PM Pctl \n                          0                           0 \n             Drinking Water         Drinking Water Pctl \n                         28                          28 \n                       Lead                   Lead Pctl \n                         96                          96 \n                 Pesticides             Pesticides Pctl \n                          0                           0 \n               Tox. Release           Tox. Release Pctl \n                          0                           0 \n                    Traffic                Traffic Pctl \n                         35                          35 \n              Cleanup Sites          Cleanup Sites Pctl \n                          0                           0 \n        Groundwater Threats    Groundwater Threats Pctl \n                          0                           0 \n                 Haz. Waste             Haz. Waste Pctl \n                          0                           0 \n          Imp. Water Bodies      Imp. Water Bodies Pctl \n                          0                           0 \n                Solid Waste            Solid Waste Pctl \n                          0                           0 \n           Pollution Burden      Pollution Burden Score \n                          0                           0 \n      Pollution Burden Pctl                      Asthma \n                          0                          11 \n                Asthma Pctl            Low Birth Weight \n                         11                         227 \n      Low Birth Weight Pctl      Cardiovascular Disease \n                        227                          11 \nCardiovascular Disease Pctl                   Education \n                         11                         103 \n             Education Pctl        Linguistic Isolation \n                        103                         320 \n  Linguistic Isolation Pctl                     Poverty \n                        320                          75 \n               Poverty Pctl                Unemployment \n                         75                         335 \n          Unemployment Pctl              Housing Burden \n                        335                         145 \n        Housing Burden Pctl                  Pop. Char. \n                        145                         103 \n           Pop. Char. Score             Pop. Char. Pctl \n                        103                         103 \n\npollution_data |&gt;\n  filter(if_any(everything(), is.na)) |&gt;\n  select(\"Census Tract\", \"California County\") |&gt;\n  count(`California County`, sort = TRUE)\n\n# A tibble: 53 × 2\n   `California County`     n\n   &lt;chr&gt;               &lt;int&gt;\n 1 Los Angeles           155\n 2 Riverside              61\n 3 Orange                 45\n 4 San Diego              38\n 5 San Bernardino         35\n 6 Sacramento             23\n 7 Alameda                22\n 8 Fresno                 17\n 9 Placer                 16\n10 Ventura                16\n# ℹ 43 more rows"
  },
  {
    "objectID": "posts/2025-04-14-blog-post-6/blog-post-6.html",
    "href": "posts/2025-04-14-blog-post-6/blog-post-6.html",
    "title": "Blog Post 6",
    "section": "",
    "text": "This week, our group is focusing on wrapping up the Analysis page by continuing to explore deeper relationships in the data and refining our modeling approach. Based on the professor’s feedback, we are rethinking how we handle missing values—moving away from simple averaging and testing more meaningful imputation strategies. We’re also in the process of building multivariate models to better understand the impact of variables like race, age, and income level on pollution scores. Our goal is to uncover patterns that might explain why certain communities experience higher pollution burdens. As part of this, we’re diving into additional variables that could influence environmental vulnerability. This will help us transition smoothly into planning the Big Picture page, where we’ll synthesize these findings to highlight broader trends and implications for environmental justice policy."
  },
  {
    "objectID": "posts/2025-04-14-blog-post-6/blog-post-6.html#updates",
    "href": "posts/2025-04-14-blog-post-6/blog-post-6.html#updates",
    "title": "Blog Post 6",
    "section": "",
    "text": "This week, our group is focusing on wrapping up the Analysis page by continuing to explore deeper relationships in the data and refining our modeling approach. Based on the professor’s feedback, we are rethinking how we handle missing values—moving away from simple averaging and testing more meaningful imputation strategies. We’re also in the process of building multivariate models to better understand the impact of variables like race, age, and income level on pollution scores. Our goal is to uncover patterns that might explain why certain communities experience higher pollution burdens. As part of this, we’re diving into additional variables that could influence environmental vulnerability. This will help us transition smoothly into planning the Big Picture page, where we’ll synthesize these findings to highlight broader trends and implications for environmental justice policy."
  },
  {
    "objectID": "posts/2025-03-31-blog-post-4/blog-post-4.html",
    "href": "posts/2025-03-31-blog-post-4/blog-post-4.html",
    "title": "Blog Post 4",
    "section": "",
    "text": "In this analysis, we extend our exploratory data analysis (EDA) by investigating the relationships between pollution burden and demographic variables across California census tracts. Our goal is to determine whether the pollution burden disproportionately affects certain racial groups and to model this relationship statistically. By considering both breadth and depth in our analysis, we aim to uncover key trends that inform environmental justice discussions."
  },
  {
    "objectID": "posts/2025-03-31-blog-post-4/blog-post-4.html#statistical-modeling",
    "href": "posts/2025-03-31-blog-post-4/blog-post-4.html#statistical-modeling",
    "title": "Blog Post 4",
    "section": "Statistical Modeling",
    "text": "Statistical Modeling\nTo formally assess the relationship between demographic composition and pollution burden, we fitted a multiple linear regression model:\ny = x1 + x2 + x3 + x4 + x5 + x6\nWhere:\ny = Pollution Burden Score &lt;- our predictor variable\nx1 = Hispanic (%)\nx2 = African American (%)\nx3 = Asian American (%)\nx4 = Native American (%)\nx5 = Other/Multiple (%)\nOur model estimates indicate that higher percentages of Hispanic, African American, and Asian American populations are associated with increased pollution burden, while Native American and Other/Multiple groups show weaker associations.\nFigure 3: Demographic Predictors of Pollution Burden"
  },
  {
    "objectID": "posts/2025-03-31-blog-post-4/blog-post-4.html#next-steps",
    "href": "posts/2025-03-31-blog-post-4/blog-post-4.html#next-steps",
    "title": "Blog Post 4",
    "section": "Next Steps:",
    "text": "Next Steps:\nOur analysis suggests that the pollution burden is not evenly distributed across demographic groups, with Hispanic and African American communities experiencing the highest pollution levels. Further analysis could include: - Exploring non-linear models or interaction effects. - Incorporating socioeconomic factors such as income and housing density. - Investigating potential policy interventions for mitigating disparities. - Through continued analysis, we hope to contribute to a better understanding of environmental justice in California."
  },
  {
    "objectID": "posts/2025-03-24-blog-post-3/blog-post-3.html",
    "href": "posts/2025-03-24-blog-post-3/blog-post-3.html",
    "title": "Blog Post 3",
    "section": "",
    "text": "Our Progress\nOver the past week, we made substantial progress in preparing our dataset for analysis. The original data came from the CalEnviroScreen 4.0 Excel file, which included multiple sheets—one containing pollution and environmental exposure data, and another with demographic indicators. We exported each sheet into separate CSV files, resulting in pollution_data.csv and demographic_data.csv. These were then read into R using read_csv() and merged using a left join on the “Census Tract” column to retain all pollution records while appending demographic information wherever available. After the merge, we removed several columns that were not directly relevant to our analysis, such as “Drinking Water”, “Groundwater Threats”, “Unemployment”, and “Housing Burden”, using a loop with select(-contains(…)). This approach allowed us to cleanly remove both the original and duplicated columns (e.g., .x, .y suffixes) introduced during merging.\nWe also addressed missing values by running colSums(is.na(cleaned_dataset)) to identify which variables had the most missing data. After reviewing the results—where “Low Birth Weight” had the highest number of NA values—we chose to drop all rows with missing values using drop_na() to ensure a clean dataset moving forward.\nLooking ahead, we plan to begin our exploratory data analysis by visualizing how pollution exposure correlates with demographic indicators such as race, age, and income. We are also beginning to consider additional data sources that could enrich our analysis—such as housing data, health outcome statistics, or climate-related variables—to explore deeper patterns of environmental injustice and vulnerability across California communities.\n\n\nData for Equity\nThe beneficence principle applies where we have to be transparent about the limits of the data when processing and analyzing our data because we can only draw a limited number of conclusions using only the columns we have. Despite any wishes we may have to extend arguments to what causes the air pollution in some neighborhoods compared to others, our dataset only focuses on the pollution and health impacts without collecting data on how the neighborhoods may be developed infrastructurally to affect these outcomes. Regardless of what analytics we produce, we don’t have the data to make claims that the increased pollution is directly caused by any of the variables we have. In addition, we should also be clear about how any previous analysis done on the dataset informed our own analysis.\nAnother principle that applies is justice. When conceiving the idea of the project, we should be clear on what the analysis would contribute to the communities it would affect. Although we may not be able to hold listening communities, we as analysts can take the responsibility to research more on the background of how air pollution can negatively impact vulnerable communities in California, and also understand the current state of what is being done to try and address the issue. For this dataset, there could be potential abuse or misuse if we try to conclude more about what causes the increased pollution, which would be not informed by the data we have available. Also, by understanding if communities are disproportionately impacted by air pollution, there is potential that the analysis could be used to support projects that push for developments in these neighborhoods that may not necessarily be wanted by the community."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This comes from the file about.qmd.\nThis is a website for the final project for MA[46]15 Data Science with R by Team TEAMNAME. The members of this team are below."
  },
  {
    "objectID": "about.html#hannah-choe",
    "href": "about.html#hannah-choe",
    "title": "About",
    "section": "Hannah Choe",
    "text": "Hannah Choe\nHannah is a junior majoring in Data Science and minoring in Business Administration Github"
  },
  {
    "objectID": "about.html#rachel-young",
    "href": "about.html#rachel-young",
    "title": "About",
    "section": "Rachel Young",
    "text": "Rachel Young\nRachel is a senior studying Data Science. Github"
  },
  {
    "objectID": "about.html#thao-thiem",
    "href": "about.html#thao-thiem",
    "title": "About",
    "section": "Thao Thiem",
    "text": "Thao Thiem\nThao is a junior studying BA/MA in Econ and Maths. Github"
  },
  {
    "objectID": "about.html#wenbo-huang",
    "href": "about.html#wenbo-huang",
    "title": "About",
    "section": "Wenbo Huang",
    "text": "Wenbo Huang\nWenbo is a junior studying math and stats. Github"
  },
  {
    "objectID": "about.html#cuichen-li",
    "href": "about.html#cuichen-li",
    "title": "About",
    "section": "Cuichen Li",
    "text": "Cuichen Li\nCuichen is a junior, studying stats and econ. Github"
  },
  {
    "objectID": "about.html#section",
    "href": "about.html#section",
    "title": "About",
    "section": "",
    "text": "About this Template.\nThis is based off of the standard Quarto website template from RStudio (2023.09.0 Build 463)."
  },
  {
    "objectID": "big_picture.html",
    "href": "big_picture.html",
    "title": "Big Picture",
    "section": "",
    "text": "This comes from the file big_picture.qmd.\nThink of this page as your 538/Upshot style article. This means that you should try to tell a story through the data and your analysis. Read articles from those sites and similar sites to get a feeling for what they are like. Try to write in the style of a news or popular article. Importantly, this page should be geared towards the general public. You shouldn’t assume the reader understands how to interpret a linear regression or a complicated plot. Focus on interpretation and visualizations."
  },
  {
    "objectID": "big_picture.html#rubric-on-this-page",
    "href": "big_picture.html#rubric-on-this-page",
    "title": "Big Picture",
    "section": "Rubric: On this page",
    "text": "Rubric: On this page\n\nTitle\n\nYour big picture page should have a creative/click-bait-y title/headline that provides a hint about your thesis.\n\nClarity of Explanation\n\nYou should have a clear thesis/goal for this page. What are you trying to show? Make sure that you explain your analysis in detail but don’t go into top much mathematics or statistics. The audience for this page is the general public (to the extent possible). Your thesis should be a statement, not a question.\nEach figure should be very polished and also not too complicated. There should be a clear interpretation of the figure so the figure has a clear purpose. Even something like a histogram can be difficult to interpret for non-experts.\n\nCreativity\n\nDo your best to make things interesting. Think of a how a news article or a magazine story might draw you in. Think of how each part of your analysis supports the previous part or provides a different perspective.\n\nInteractive component\n\nQuality and ease of use of the interactive components. Is it clear what can be explored using your interactive components? Does it enhance and reinforce your conclusions?\n\nThis page should be self-contained.\n\nNote: This page should have no code visible, i.e. use #| echo: FALSE."
  },
  {
    "objectID": "big_picture.html#rubric-other-components",
    "href": "big_picture.html#rubric-other-components",
    "title": "Big Picture",
    "section": "Rubric: Other components",
    "text": "Rubric: Other components\n\nVideo Recording\nMake a video recording (probably using Zoom) demonstrating your interactive components. You should provide a quick explanation of your data and demonstrate some of the conclusions from your EDA. This video should be no longer than 4 minutes. Include a link to your video (and password if needed) in your README.md file on your Github repository. You are not required to provide a link on the website. This can be presented by any subset of the team members.\n\n\nRest of the Site\nFinally, here are important things to keep in mind for the rest of the site.\nThe main title of your page is informative. Each post has an author/description/informative title. All lab required posts are present. Each page (including the home page) has a nice featured image associated with it. Your about page is up to date and clean. You have removed the generic posts from the initial site template."
  }
]