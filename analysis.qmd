---
title: Analysis
description: Here we provide a detailed analysis using more sophisticated statistics techniques.
toc: true
draft: false
---


![](images/air_quality.jpg)


We describe here our detailed data analysis. This page will provide an overview of what questions you addressed, illustrations of relevant aspects of the data with tables and figures, and a statistical model that attempts to answer part of the question. You'll also reflect on next steps and further analysis.

The audience for this page is someone like your class mates, so you can expect that they have some level of statistical and quantitative sophistication and understand ideas like linear and logistic regression, coefficients, confidence intervals, overfitting, etc.

While the exact number of figures and tables will vary and depend on your analysis, you should target around 5 to 6. An overly long analysis could lead to losing points. If you want you can link back to your blog posts or create separate pages with more details.

The style of this paper should aim to be that of an academic paper. I don't expect this to be of publication quality but you should keep that aim in mind. Avoid using "we" too frequently, for example "We also found that ...". Describe your methodology and your findings but don't describe your whole process.

## Rubric: On this page

You will

-   Introduce what motivates your Data Analysis (DA)
    -   Which variables and relationships are you most interested in?
    -   What questions are you interested in answering?
    -   Provide context for the rest of the page. This will include figures/tables that illustrate aspects of the data of your question.
-   Modeling and Inference
    -   The page will include some kind of formal statistical model. This could be a linear regression, logistic regression, or another modeling framework.
    -   Explain the ideas and techniques you used to choose the predictors for your model. (Think about including interaction terms and other transformations of your variables.)
    -   Describe the results of your modelling and make sure to give a sense of the uncertainty in your estimates and conclusions.
-   Explain the flaws and limitations of your analysis
    -   Are there some assumptions that you needed to make that might not hold? Is there other data that would help to answer your questions?
-   Clarity Figures
    -   Are your figures/tables/results easy to read, informative, without problems like overplotting, hard-to-read labels, etc?
    -   Each figure should provide a key insight. Too many figures or other data summaries can detract from this. (While not a hard limit, around 5 total figures is probably a good target.)
    -   Default `lm` output and plots are typically not acceptable.
-   Clarity of Explanations
    -   How well do you explain each figure/result?
    -   Do you provide interpretations that suggest further analysis or explanations for observed phenomenon?
-   Organization and cleanliness.
    -   Make sure to remove excessive warnings, hide all code, organize with sections or multiple pages, use bullets, etc.
    -   This page should be self-contained, i.e. provide a description of the relevant data.


## Introduction

### Motivation

The analysis aims to investigate the relationship between demographic factors (e.g., race, ethnicity) and pollution burden in Californiaâ€™s census tracts. Understanding these relationships is essential for targeting environmental policies that mitigate pollution's impact on vulnerable communities. By examining how demographic characteristics influence the pollution burden, we can highlight areas that may need focused intervention to reduce environmental inequities.

### Key Questions

We are particularly interested in understanding how the proportion of Hispanic, African American, and Asian American populations within census tracts correlates with the pollution burden score. Specifically, we seek to answer the following questions:

- How does the percentage of each racial/ethnic group (Hispanic, African American, Asian American, etc.) correlate with the pollution burden score in California census tracts?

- Are certain demographic groups more likely to live in high-pollution areas?

To explore these questions, we present visualizations and statistical models that analyze these relationships. The following figures and tables will provide insights into the distribution of demographic groups, the extent of pollution in different counties, and the impact of racial composition on pollution levels.


## Data Overview and Inital Exploration

## Data Visualization

```{r}
#| echo: false
#| message: false
#| warning: false

library(tidyverse)
library(dplyr)
library(ggplot2)
data <- read_rds(here::here("dataset/cleaned_dataset.rds"))
pollution_data <- read_rds(here::here("dataset/pollution_data.rds"))
demographic_data <- read_rds(here::here("dataset/demographic_data.rds"))
```

For each census tract, races that are non-white tend to have smaller population percentages that are less than 25% of the census tract.

```{r}
demo_long <- demographic_data |>
  pivot_longer(cols = c(`Hispanic (%)`, `White (%)`, `African American (%)`, `Native American (%)`,`Asian American (%)`,`Other/Multiple (%)`),
               names_to = "Race",
               values_to = "Percentage")

ggplot(demo_long, aes(x = Percentage)) +
  geom_histogram(binwidth = 5) + 
  facet_wrap(~Race, scales = "free_y") + 
  labs(title = "Distribution of Race Percentages",
       x = "Percentage",
       y = "Frequency")
```

Pollution vs. Race

```{r}
ggplot(data, aes(x = `Hispanic (%)`, y = `Pollution Burden Score`)) +
  geom_point(alpha = 0.3, color = "darkgreen") +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  labs(title = "Pollution Burden vs. Hispanic")
```

Top 10 Most Polluted Counties

```{r}
data %>%
  group_by(`California County`) %>%
  summarise(mean_pollution = mean(`Pollution Burden Score`, na.rm = TRUE)) %>%
  top_n(10, mean_pollution) %>%
  ggplot(aes(x = reorder(`California County`, mean_pollution), y = mean_pollution)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(title = "Top 10 Most Polluted Counties", x = NULL, y = "Avg. Pollution Score")
```



```{r}
ggplot(data, aes(x = `Pollution Burden Score`, y = `Asthma`)) +
  geom_point(alpha = 0.3, color = "orange") +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  labs(title = "Pollution Burden vs. Asthma Rate",
       x = "Pollution Burden Score",
       y = "Asthma Rate")
```


```{r}
library(corrplot)

exclude_vars <- c("CES 4.0 Score", "CES 4.0 Percentile", "CES 4.0 Percentile Range", "Pollution                        Burden Pctl")

numeric_data <- data |>
  select_if(is.numeric) |>
  select(-one_of(exclude_vars))

correlation_matrix_filtered <- cor(numeric_data, use = "complete.obs")

pollution_burden_corr <- correlation_matrix_filtered["Pollution Burden Score",]

sorted_corr <- sort(abs(pollution_burden_corr), decreasing = TRUE)

top_10_variables <- names(sorted_corr[2:11])

top_corr_matrix <- correlation_matrix_filtered[top_10_variables, top_10_variables]

corrplot(top_corr_matrix, 
         method = "color", 
         type = "upper", 
         title = "Top 10 Variables Correlated with Pollution Burden Score (Excluding CES 4.0 Score)", 
         tl.cex = 0.7, 
         tl.srt = 45, # Rotate text labels for readability
         mar = c(0, 0, 3, 0), # Increase space around the plot
         number.cex = 0.7) # Adjust number size

```

### Modeling and Inference
```{r}
coef_plot <- ggplot(data.frame(
  term = c("Hispanic", "African American", "Asian American", 
           "Native American", "Other/Multiple"),
  estimate = c(0.030, 0.018, 0.013, 0.006, -0.016),
  ci_lower = c(0.029, 0.015, 0.011, -0.007, -0.030),
  ci_upper = c(0.031, 0.022, 0.015, 0.020, -0.002)
), aes(x = estimate, y = term)) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "gray50") +
  geom_point(size = 2) +
  geom_errorbarh(aes(xmin = ci_lower, xmax = ci_upper), height = 0.2) +
  labs(title = "Demographic Predictors of Pollution Burden",
       subtitle = "Coefficient estimates with 95% confidence intervals",
       x = "Effect Size (Change in Pollution Score per 1% Increase)",
       y = "Demographic Group") +
  theme_minimal()

print(coef_plot)
```


## Models
### Full Model on Original Data

We begin with a linear model that includes all predictors without transformation.

```{r}
#| echo: false
#| message: false
#| warning: false


library(broom)
library(gt)
library(modelsummary)
model <- lm(`Pollution Burden Score` ~ ., data = data)
```

#### Residual Diagnostics

```{r}
# Residuals vs Fitted Plot
plot(model$fitted.values, model$residuals,
     xlab = "Fitted Values", ylab = "Residuals",
     main = "Residuals vs Fitted (Original)")
abline(h = 0, col = "red")

# Q-Q Plot
qqnorm(model$residuals)
qqline(model$residuals, col = "red")
```

These plots indicate non-normal residuals and possible heteroscedasticity, suggesting that transformation may improve model fit.



### Log Transformation of Response

To address non-constant variance and skewness in the response, we log-transform the Pollution Burden Score.

```{r}
model_log <- lm(log(`Pollution Burden Score`) ~ ., data = data)
```

#### Residual Diagnostics

```{r}
# Residuals vs Fitted
plot(model_log$fitted.values, model_log$residuals,
     xlab = "Fitted Values", ylab = "Residuals",
     main = "Residuals vs Fitted (Log y)")
abline(h = 0, col = "red")

# Q-Q Plot
qqnorm(model_log$residuals)
qqline(model_log$residuals, col = "red")
```

Some improvement is seen, but the residual patterns still suggest potential nonlinearity in predictors.



### Log-Log Model

We apply a log transformation to both the response and log-safe numeric predictors.

```{r}
library(dplyr)

# Copy dataset
log_data <- data

# Ensure all column names are clean (remove weird spaces)
colnames(log_data) <- trimws(colnames(log_data))

# Get numeric predictors, excluding the response
numeric_vars <- names(log_data)[
  sapply(log_data, is.numeric) & names(log_data) != "Pollution Burden Score"
]

# Remove variables with any non-positive or missing values
log_friendly_vars <- numeric_vars[
  sapply(log_data[numeric_vars], function(x) all(is.finite(x) & x > 0))
]

# Log-transform those safely
log_data <- log_data %>%
  mutate(across(all_of(log_friendly_vars), log))

# Log-transform the response
log_data$log_score <- log(log_data$`Pollution Burden Score`)

log_log_model <- lm(log_score ~ ., data = log_data %>% select(-`Pollution Burden Score`))
summary(log_log_model)

```

#### Residual Diagnostics

```{r}
plot(log_log_model$fitted.values, log_log_model$residuals,
     xlab = "Fitted Values", ylab = "Residuals",
     main = "Residuals vs Fitted: Log-Log Model")
abline(h = 0, col = "red")

qqnorm(log_log_model$residuals)
qqline(log_log_model$residuals, col = "red")
```

The log-log model displays better residual behavior and improved normality, supporting its use moving forward.


### Multicollinearity Check

We assess multicollinearity among predictors using Variance Inflation Factors (VIF).

```{r}
#| echo: false
#| message: false
#| warning: false

library(car)
library(tidyverse)

log_data_clean <- log_data %>% select(-`Approximate Location`)

log_log_model_clean <- lm(log_score ~ ., data = log_data_clean)

vif(log_log_model_clean)
```

Predictors such as demographic percentages and county indicators show high VIFs, indicating multicollinearity. We consider transformation and selection to reduce redundancy.

```{r}
log_data <- data %>%
  mutate(across(
    c(`Pollution Burden Score`,
      Ozone, `PM2.5`, `Diesel PM`, Traffic,
      `Cleanup Sites`, `Haz. Waste`, `Solid Waste`,
      Asthma, `Low Birth Weight`, `Cardiovascular Disease`,
      `Children < 10 years (%)`, `Elderly > 64 years (%)`, `White (%)`,
      `Hispanic (%)`, `African American (%)`, `Asian American (%)`),
    ~ log(. + 1)
  ))

log_log_model <- lm(`Pollution Burden Score` ~ 
  Ozone + `PM2.5` + `Diesel PM` + Traffic +
  `Cleanup Sites` + `Haz. Waste` + `Solid Waste` +
  Asthma + `Low Birth Weight` + `Cardiovascular Disease` +
  `Children < 10 years (%)` + `Elderly > 64 years (%)` + 
  `Hispanic (%)` + `African American (%)` + `Asian American (%)` + `White (%)`,
  `California County`,
  data = log_data)

summary(log_log_model)

```

### Variable Selection

We compare backward selection and forward selection based on AIC.

#### Backward Selection

```{r}
backward_model <- step(log_log_model, direction = "backward")
summary(backward_model)
```

#### Forward Selection

```{r}
forward_model <- step(log_log_model, direction = "forward")
summary(forward_model)
```

Backward selection slightly outperformed forward selection:

- AIC (Backward): -61859.36
- AIC (Forward): -61856.87

Both models had the same Adjusted RÂ² (â‰ˆ 0.8597), but the backward model:
- Used fewer predictors (14 vs. 16),
- Removed two unhelpful variables (PM2.5, Low Birth Weight),
- Is thus more parsimonious and interpretable.

We select the backward model as our final model.

## Final Model Summary

Our final model includes key environmental and demographic factors, along with county fixed effects:

```{r}
summary(backward_model)
```

This model strikes a balance between interpretability and predictive power, with improved residual diagnostics and lower AIC compared to the full model.
