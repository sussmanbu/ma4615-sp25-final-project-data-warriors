---
title: Analysis
description: Here we provide a detailed analysis using more sophisticated statistics techniques.
toc: true
draft: false
---


![](images/image2.jpg)

## Introduction

### Motivation

The analysis aims to investigate the relationship between demographic factors (e.g., race, ethnicity) and pollution burden in Californiaâ€™s census tracts. Understanding these relationships is essential for targeting environmental policies that mitigate pollution's impact on vulnerable communities. By examining how demographic characteristics influence the pollution burden, we can highlight areas that may need focused intervention to reduce environmental inequities.

### Key Questions

We are particularly interested in understanding how the proportion of Hispanic, African American, and Asian American populations within census tracts correlates with the pollution burden score. Specifically, we seek to answer the following questions:

- How does the percentage of each racial/ethnic group (Hispanic, African American, Asian American, etc.) correlate with the pollution burden score in California census tracts?

- Are certain demographic groups more likely to live in high-pollution areas?

To explore these questions, we present visualizations and statistical models that analyze these relationships. The following figures and tables will provide insights into the distribution of demographic groups, the extent of pollution in different counties, and the impact of racial composition on pollution levels.


## Data Overview and Inital Exploration

### Data Visualization

```{r}
#| echo: false
#| message: false
#| warning: false

library(tidyverse)
library(dplyr)
library(ggplot2)
data <- read_rds(here::here("dataset/cleaned_dataset.rds"))
pollution_data <- read_rds(here::here("dataset/pollution_data.rds"))
demographic_data <- read_rds(here::here("dataset/demographic_data.rds"))
```

For each census tract, races that are non-white tend to have smaller population percentages that are less than 25% of the census tract.

```{r}
#| echo: false
#| message: false
#| warning: false
demo_long <- demographic_data |>
  pivot_longer(cols = c(`Hispanic (%)`, `White (%)`, `African American (%)`, `Native American (%)`,`Asian American (%)`,`Other/Multiple (%)`),
               names_to = "Race",
               values_to = "Percentage")

ggplot(demo_long, aes(x = Percentage)) +
  geom_histogram(binwidth = 5) + 
  facet_wrap(~Race, scales = "free_y") + 
  labs(title = "Distribution of Race Percentages",
       x = "Percentage",
       y = "Frequency")
```

Pollution vs. Race

```{r}
#| echo: false
#| message: false
#| warning: false
ggplot(data, aes(x = `Hispanic (%)`, y = `Pollution Burden Score`)) +
  geom_point(alpha = 0.3, color = "darkgreen") +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  labs(title = "Pollution Burden vs. Hispanic")
```

Top 10 Most Polluted Counties

```{r}
#| echo: false
#| message: false
#| warning: false
data %>%
  group_by(`California County`) %>%
  summarise(mean_pollution = mean(`Pollution Burden Score`, na.rm = TRUE)) %>%
  top_n(10, mean_pollution) %>%
  ggplot(aes(x = reorder(`California County`, mean_pollution), y = mean_pollution)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(title = "Top 10 Most Polluted Counties", x = NULL, y = "Avg. Pollution Score")
```



```{r}
#| echo: false
#| message: false
#| warning: false
ggplot(data, aes(x = `Pollution Burden Score`, y = `Asthma`)) +
  geom_point(alpha = 0.3, color = "orange") +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  labs(title = "Pollution Burden vs. Asthma Rate",
       x = "Pollution Burden Score",
       y = "Asthma Rate")
```


```{r}
#| echo: false
#| message: false
#| warning: false
library(corrplot)

exclude_vars <- c("CES 4.0 Score", "CES 4.0 Percentile", "CES 4.0 Percentile Range", "Pollution                        Burden Pctl")

numeric_data <- data |>
  select_if(is.numeric) |>
  select(-one_of(exclude_vars))

correlation_matrix_filtered <- cor(numeric_data, use = "complete.obs")

pollution_burden_corr <- correlation_matrix_filtered["Pollution Burden Score",]

sorted_corr <- sort(abs(pollution_burden_corr), decreasing = TRUE)

top_10_variables <- names(sorted_corr[2:11])

top_corr_matrix <- correlation_matrix_filtered[top_10_variables, top_10_variables]

corrplot(top_corr_matrix, 
         method = "color", 
         type = "upper", 
         title = "Top 10 Variables Correlated with Pollution Burden Score (Excluding CES 4.0 Score)", 
         tl.cex = 0.7, 
         tl.srt = 45, # Rotate text labels for readability
         mar = c(0, 0, 3, 0), # Increase space around the plot
         number.cex = 0.7) # Adjust number size

```

### Modeling and Inference
```{r}
#| echo: false
#| message: false
#| warning: false
coef_plot <- ggplot(data.frame(
  term = c("Hispanic", "African American", "Asian American", 
           "Native American", "Other/Multiple"),
  estimate = c(0.030, 0.018, 0.013, 0.006, -0.016),
  ci_lower = c(0.029, 0.015, 0.011, -0.007, -0.030),
  ci_upper = c(0.031, 0.022, 0.015, 0.020, -0.002)
), aes(x = estimate, y = term)) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "gray50") +
  geom_point(size = 2) +
  geom_errorbarh(aes(xmin = ci_lower, xmax = ci_upper), height = 0.2) +
  labs(title = "Demographic Predictors of Pollution Burden",
       subtitle = "Coefficient estimates with 95% confidence intervals",
       x = "Effect Size (Change in Pollution Score per 1% Increase)",
       y = "Demographic Group") +
  theme_minimal()

print(coef_plot)
```


### Models
#### Full Model on Original Data

We begin with a linear model that includes all predictors without transformation.

```{r}
#| echo: false
#| message: false
#| warning: false


library(broom)
library(gt)
library(modelsummary)
model <- lm(`Pollution Burden Score` ~ ., data = data)
```

#### Residual Diagnostics

```{r}
#| echo: false
#| message: false
#| warning: false
#| fig-width: 10
#| fig-height: 4

# Show two plots side-by-side with better spacing
par(mfrow = c(1, 2))

# Residuals vs Fitted
plot(model$fitted.values, model$residuals,
     xlab = "Fitted Values", ylab = "Residuals",
     main = "Residuals vs Fitted (Log y)")
abline(h = 0, col = "red")

# Q-Q Plot
qqnorm(model$residuals)
qqline(model$residuals, col = "red")
```

These plots indicate non-normal residuals and possible heteroscedasticity, suggesting that transformation may improve model fit.



### Log Transformation of Response

To address non-constant variance and skewness in the response, we log-transform the Pollution Burden Score.

```{r}
#| echo: false
#| message: false
#| warning: false
#
model_log <- lm(log(`Pollution Burden Score`) ~ ., data = data)
```

#### Residual Diagnostics


```{r}
#| echo: false
#| message: false
#| warning: false
#| fig-width: 10
#| fig-height: 4

# Show two plots side-by-side with better spacing
par(mfrow = c(1, 2))

# Residuals vs Fitted
plot(model_log$fitted.values, model_log$residuals,
     xlab = "Fitted Values", ylab = "Residuals",
     main = "Residuals vs Fitted (Log y)")
abline(h = 0, col = "red")

# Q-Q Plot
qqnorm(model_log$residuals)
qqline(model_log$residuals, col = "red")

# Reset plotting layout afterward
par(mfrow = c(1, 1))
```

Some improvement is seen, but the residual patterns still suggest potential nonlinearity in predictors.



### Log-Log Model

We apply a log transformation to both the response and log-safe numeric predictors.

```{r}
#| echo: false
#| message: false
#| warning: false

library(dplyr)

log_data <- data
colnames(log_data) <- trimws(colnames(log_data))

numeric_vars <- names(log_data)[
  sapply(log_data, is.numeric) & names(log_data) != "Pollution Burden Score"
]

log_friendly_vars <- numeric_vars[
  sapply(log_data[numeric_vars], function(x) all(is.finite(x) & x > 0))
]

log_data <- log_data %>%
  mutate(across(all_of(log_friendly_vars), log))

log_data$log_score <- log(log_data$`Pollution Burden Score`)

log_log_model <- lm(log_score ~ ., data = log_data %>% select(-`Pollution Burden Score`))

library(broom)
library(gt)
model_perf <- glance(log_log_model)  # again replace with your actual model

model_perf %>%
  select(r.squared, adj.r.squared, sigma, statistic, p.value, df, AIC, BIC) %>%
  gt() %>%
  tab_header(
    title = "Statistical Performance"
  ) %>%
  fmt_number(decimals = 4)
```

#### Residual Diagnostics

```{r}
#| echo: false
#| message: false
#| warning: false
#| fig-width: 10
#| fig-height: 4

# Show two plots side-by-side with better spacing
par(mfrow = c(1, 2))

# Residuals vs Fitted
plot(log_log_model$fitted.values, log_log_model$residuals,
     xlab = "Fitted Values", ylab = "Residuals",
     main = "Residuals vs Fitted (Log y)")
abline(h = 0, col = "red")

# Q-Q Plot
qqnorm(log_log_model$residuals)
qqline(log_log_model$residuals, col = "red")

# Reset plotting layout afterward
par(mfrow = c(1, 1))
```

The log-log model displays better residual behavior and improved normality, supporting its use moving forward.


### Multicollinearity Check

We assess multicollinearity among predictors using Variance Inflation Factors (VIF).

```{r}
#| echo: false
#| message: false
#| warning: false

library(car)
library(tidyverse)

log_data_clean <- log_data %>% select(-`Approximate Location`)

log_log_model_clean <- lm(log_score ~ ., data = log_data_clean)

library(gt)
library(tibble)


# Compute VIF and convert to data frame
vif_df <- car::vif(log_log_model_clean) %>%
  as.data.frame() %>%
  rownames_to_column("Variable") %>%
  rename(GVIF = 2, Df = 3, `GVIF^(1/(2*Df))` = 4)

# Filter for high GVIFs
high_vif <- vif_df %>%
  filter(`GVIF^(1/(2*Df))` > 5)

# Create the gt table
vif_table <- gt(high_vif) %>%
  tab_header(title = "Variables with High Multicollinearity (GVIF > 5)") %>%
  tab_options(table.width = pct(100))

# Render the table inside a scrollable container
htmltools::tags$div(
  style = "max-height: 300px; overflow-y: auto; border: 1px solid #ddd; padding: 0.5em;",
  gt::as_raw_html(vif_table)
)
```

Predictors such as demographic percentages and county indicators show high VIFs, indicating multicollinearity. We consider transformation and selection to reduce redundancy.

```{r}
#| echo: false
#| message: false
#| warning: false

log_data <- data %>%
  mutate(across(
    c(`Pollution Burden Score`,
      Ozone, `PM2.5`, `Diesel PM`, Traffic,
      `Cleanup Sites`, `Haz. Waste`, `Solid Waste`,
      Asthma, `Low Birth Weight`, `Cardiovascular Disease`,
      `Children < 10 years (%)`, `Elderly > 64 years (%)`, `White (%)`,
      `Hispanic (%)`, `African American (%)`, `Asian American (%)`),
    ~ log(. + 1)
  ))

log_log_model <- lm(`Pollution Burden Score` ~ 
  Ozone + `PM2.5` + `Diesel PM` + Traffic +
  `Cleanup Sites` + `Haz. Waste` + `Solid Waste` +
  Asthma + `Low Birth Weight` + `Cardiovascular Disease` +
  `Children < 10 years (%)` + `Elderly > 64 years (%)` + 
  `Hispanic (%)` + `African American (%)` + `Asian American (%)` + `White (%)`,
  `California County`,
  data = log_data)



model_perf <- glance(log_log_model)  # again replace with your actual model

model_perf %>%
  select(r.squared, adj.r.squared, sigma, statistic, p.value, df, AIC, BIC) %>%
  gt() %>%
  tab_header(
    title = "Statistical Performance"
  ) %>%
  fmt_number(decimals = 4)
```

### Variable Selection

We compare backward selection and forward selection based on AIC.

#### Backward Selection
```{r}
#| echo: false
#| message: false
#| warning: false
#| results: hide

quiet_step <- function(...) {
  capture.output(result <- step(..., trace = 0))
  return(result)
}

backward_model <- quiet_step(
  step(log_log_model, direction = "backward")
)
```

```{r}
#| echo: false
#| message: false
#| warning: false

library(broom)
library(gt)


glance(backward_model) |>
  select(r.squared, adj.r.squared, sigma, statistic, p.value, df, AIC, BIC) |>
  gt() |>
  tab_header(title = "Statistical Performance: Backward Model") |>
  fmt_number(columns = everything(), decimals = 4)
```

#### Forward Selection

```{r}
#| echo: false
#| message: false
#| warning: false
#| results: 'hide'

forward_model <- quiet_step(step(log_log_model, direction = "forward"))

glance(forward_model) |>
  select(r.squared, adj.r.squared, sigma, statistic, p.value, df, AIC, BIC) |>
  gt() |>
  tab_header(title = "Statistical Performance: Forward Model") |>
  fmt_number(columns = everything(), decimals = 4)
```

Backward selection slightly outperformed forward selection:

- AIC (Backward): -61859.36
- AIC (Forward): -61856.87

Both models had the same Adjusted RÂ² (â‰ˆ 0.8597), but the backward model:
- Used fewer predictors (14 vs. 16),
- Removed two unhelpful variables (PM2.5, Low Birth Weight),
- Is thus more parsimonious and interpretable.

We select the backward model as our final model.

## Final Model Summary

Our final model includes key environmental and demographic factors, along with county fixed effects:

```{r}
#| echo: false
#| message: false
#| warning: false

library(broom)
library(gt)

backward_model %>%
  tidy(conf.int = TRUE) %>%
  mutate(term = ifelse(term == "(Intercept)", "Intercept", term)) %>%
  gt() %>%
  tab_header(
    title = "Backward Model Coefficients",
    subtitle = "Estimates with 95% Confidence Intervals"
  ) %>%
  fmt_number(columns = where(is.numeric), decimals = 3)

```

This model strikes a balance between interpretability and predictive power, with improved residual diagnostics and lower AIC compared to the full model.

### Limitations and Assumptions

As with any linear regression analysis, our model relies on several assumptions: linearity between predictors and response, homoscedasticity (constant variance), independence of observations, and normality of residuals. While the log-log transformation improved residual behavior, some mild skewness and heteroscedasticity may remain. Furthermore, multicollinearity among demographic variables was mitigated but not eliminated entirely.

Additionally, this analysis does not account for potential spatial correlation between neighboring tracts or time-varying pollution dynamics. Including temporal or spatial random effects, or using generalized additive models, could improve the robustness of our findings. Incorporating socioeconomic indicators such as income, education, and housing density would also enhance our understanding of environmental inequity.
