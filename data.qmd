---
title: Data
description: We describe the sources of our data and the cleaning process.
toc: true
draft: false
---

![](images/logo.png)


## Data Description

The CalEnviroScreen data, available for download at ["OEHHA’s website"](https://www.google.com/url?q=https://oehha.ca.gov/calenviroscreen/download-data&sa=D&source=docs&ust=1742852733483866&usg=AOvVaw35FXwtWKeysE4tXW15G9nc), is compiled by the Office of Environmental Health Hazard Assessment (OEHHA) under the California Environmental Protection Agency (CalEPA). This dataset is designed to assess cumulative environmental burdens and population vulnerabilities across California’s communities, specifically at the census tract level. It includes indicators on pollution exposure, environmental effects, sensitive populations, and socioeconomic factors, allowing policymakers, researchers, and the public to identify areas most impacted by environmental hazards. The data was collected to support state efforts in environmental justice and resource allocation, particularly to assist in directing funding and policy initiatives to disadvantaged communities. By integrating environmental and demographic data, CalEnviroScreen provides a comprehensive tool for understanding disparities in environmental health risks across the state.

The data has been used for research in the San Ysidro, California community because it's located near the world's busiest border crossing. Residents were predominately from marginalized communities and had complained that government air monitoring did not adequately measure air quality in their community. By collaborating with the San Ysidro community in San Diego, the OEHHA was able to collect data using low-cost technology to prioritize funding for identifying California communities with higher pollution burden scores and demographic vulnerabilities. 

The CalEnviroScreen data has been used effectively in identifying the affected communities hence calling for policy action to direct cap-and-trade revenues to highly impacted areas, and also has been updated over the years to include more indicators and greater geographic specificity. This information is used by policymakers to allocate funds for environmental justice, guide regulatory enforcement, and support programs that target pollution control and public health improvements.

## Data Files and Description
The original data was downloaded from CalEnviroScreen 4.0, which provides statewide data on environmental and demographic indicators at the census tract level. The data came in a single [Excel file](https://oehha.ca.gov/media/downloads/calenviroscreen/document/calenviroscreen40resultsdatadictionaryf2021.zip) with multiple sheets. One sheet contained pollution and environmental exposure indicators, while another contained population and demographic characteristics. To prepare the data for analysis, we extracted each of these sheets and saved them as separate CSV files: `pollution_data.csv` and `demographic_data.csv`.

The `pollution_data.csv` file includes key variables such as `Ozone`, `PM2.5`, `Diesel PM`, and `Traffic`, along with their respective percentiles (e.g., "Ozone Pctl", "PM2.5 Pctl"). These values quantify the level of environmental pollution affecting each census tract. It also includes summary indicators such as "Pollution Burden Score" and "CES 4.0 Score", which are composite measures used by the state to assess environmental vulnerability.

The `demographic_data.csv` file contains population-level statistics, including `Total Population`, `Children < 10 years (%)`, and `Elderly > 64 years (%)`, as well as racial and ethnic breakdowns such as `Hispanic (%)`, `African American (%)`, and `Asian American (%)`. These demographic variables allow for an assessment of how pollution levels intersect with age and race across regions.

To simplify the analysis, we focused on the most relevant environmental and demographic variables and removed columns related to less directly useful metrics like groundwater threats, education, and unemployment. Together, the cleaned and merged dataset allows us to explore the relationship between environmental burdens and community demographics in California.

#### *Variable description:*

Key variables include:

**Environmental Related statistics**: like `Pollution Burden Score`, which is a score scaled from 1 -10 and weighs both environmental effects and pollution indictors. It  is the outcome variable we're attempting to measure the effect size with.

**Location**: California county that the census tract falls within

**Race**: The percentage of each racial group in each census tract.

**Other related statistics**: Like poverty, education level, unemployment rate, Housing burden, Birth weight, potentially revealing relationships between those statistics and environmental levels.

#### **Official Data Dictionary:**
```{r}
#| echo: false
#| message: false
#| warning: false

variable_table <- data.frame(
  Variable = c(
    "Census Tract", "Total Population", "California County", "ZIP", "Approximate Location",
    "Longitude", "Latitude", "CES 4.0 Score", "CES 4.0 Percentile", "CES 4.0 Percentile Range",
    "Ozone", "Ozone Pctl", "PM2.5", "PM2.5 Pctl", "Diesel PM", "Diesel PM Pctl",
    "Tox. Release", "Tox. Release Pctl", "Traffic", "Traffic Pctl", "Cleanup Sites",
    "Cleanup Sites Pctl", "Haz. Waste", "Haz. Waste Pctl", "Solid Waste", "Solid Waste Pctl",
    "Pollution Burden", "Pollution Burden Score", "Pollution Burden Pctl", "Asthma",
    "Asthma Pctl", "Low Birth Weight", "Low Birth Weight Pctl", "Cardiovascular Disease",
    "Cardiovascular Disease Pctl", "Pop. Char.", "Pop. Char. Score", "Pop. Char. Pctl",
    "Children < 10 years (%)", "Pop 10–64 years (%)", "Elderly > 64 years (%)",
    "Hispanic (%)", "White (%)", "African American (%)", "Native American (%)",
    "Asian American (%)", "Other/Multiple (%)"
  ),
  Description = c(
    "Census Tract ID from the 2010 Census",
    "Estimated population in each census tract (2019 ACS)",
    "County in which each census tract is located",
    "ZIP code for each census tract",
    "Approximate city or area name based on boundary files",
    "Longitude of the census tract centroid",
    "Latitude of the census tract centroid",
    "Final CalEnviroScreen score (Pollution Burden × Pop. Characteristics)",
    "Statewide percentile of the CES score",
    "Grouped CES percentile (e.g., 0–5%, 5–10%, etc.)",
    "Daily max 8-hour ozone concentration",
    "Ozone percentile",
    "Annual average PM2.5 concentration",
    "PM2.5 percentile",
    "Diesel particulate emissions from transportation",
    "Diesel PM percentile",
    "Toxic air releases from facilities (modeled)",
    "Toxic release percentile",
    "Traffic density near census tract boundary",
    "Traffic percentile",
    "Count of cleanup sites weighted by proximity",
    "Cleanup sites percentile",
    "Hazardous waste sites/facilities",
    "Hazardous waste percentile",
    "Solid waste sites/facilities",
    "Solid waste percentile",
    "Average of pollution percentiles (weighted)",
    "Scaled pollution burden score (0–10)",
    "Pollution burden percentile",
    "Emergency department visit rate for asthma",
    "Asthma percentile",
    "Percent of low birth weight infants",
    "Low birth weight percentile",
    "Emergency visit rate for heart attacks",
    "Cardiovascular disease percentile",
    "Average of population vulnerability percentiles",
    "Scaled population characteristics score (0–10)",
    "Population characteristics percentile",
    "Percent of population under age 10",
    "Percent of population aged 10–64",
    "Percent of population over age 64",
    "Percent identifying as Hispanic or Latino",
    "Percent identifying as non-Hispanic White",
    "Percent identifying as non-Hispanic Black",
    "Percent identifying as non-Hispanic Native American",
    "Percent identifying as non-Hispanic Asian",
    "Percent identifying as other or multiple races"
  )
)
```



```{r}
#| echo: false
#| message: false
#| warning: false

library(tidyverse)
library(dplyr)
library(ggplot2)
data <- read_rds(here::here("dataset/cleaned_dataset.rds"))
pollution_data <- read_rds(here::here("dataset/pollution_data.rds"))
demographic_data <- read_rds(here::here("dataset/demographic_data.rds"))

library(gt)

variable_table %>%
  gt() %>%
  cols_width(
    Variable ~ px(200),        # Widen the 'Variable' column
    Description ~ px(500)      # Widen the 'Description' column
  ) %>%
  tab_options(
    data_row.padding = px(6),  # Add vertical padding between rows
    table.width = pct(120)     # Make table span full content width
  )

```

### Dataset Distribution
```{r}
#| echo: false
#| message: false
#| warning: false

ggplot(data, aes(x = `Pollution Burden Score`)) +
  geom_histogram(binwidth = 1, fill = "steelblue", color = "black", alpha = 0.7) +
  labs(title = "Distribution of Pollution Burden Scores",
       x = "Pollution Burden Score",
       y = "Frequency") +
  theme_minimal()
```
The histogram above illustrates the distribution of Pollution Burden Scores in California, which shows that pollution scores are fairly normally distributed among all census tracts. The pollution score with the highest frequency observed is 5.0. However, our project aims to determine if census tracts with greater pollution scores might be communities with higher racial/ethnic minority populations. 


```{r}
#| echo: false
#| message: false
#| warning: false
#| 
demo_long <- data %>%
  pivot_longer(cols = c(`Hispanic (%)`, `White (%)`, `African American (%)`, `Native American (%)`, 
                        `Children < 10 years (%)`, `Pop 10-64 years (%)`, `Elderly > 64 years (%)`),
               names_to = "Demographic", values_to = "Percentage")


ggplot(demo_long, aes(x = Demographic, y = Percentage, fill = Demographic)) +
  geom_boxplot() +
  labs(title = "Boxplot of Demographic Percentages Across Census Tracts",
       x = "Demographic Group",
       y = "Percentage of Population") +
  theme_minimal() +
  coord_flip() 

```

The boxplots above shows the distribution of the percentage of demographics in each census tract. We observed that census tracts with a higher percentages of individuals in the age range 10 to 64 years old were more common, and that so were census tracts with higher percentages of White individuals. However, the distribution seems to be widely dispersed with various outliers for each demographic catergory. 

```{r}
#| echo: false
library(dplyr)
library(tidyr)
library(gt)

# Use this version to safely exclude ZIP only if it's present



# === NUMERICAL SUMMARY TABLE ===

numeric_summary <- data %>%
  select(where(is.numeric), -ZIP) %>%  # Exclude ZIP code
  summarise(across(
    everything(),
    list(
      Mean = ~mean(., na.rm = TRUE),
      Median = ~median(., na.rm = TRUE),
      Minimum = ~min(., na.rm = TRUE),
      Maximum = ~max(., na.rm = TRUE)
    ),
    .names = "{.col}_{.fn}"
  )) %>%
  pivot_longer(everything(), names_to = c("Variable", "Statistic"), names_sep = "_") %>%
  pivot_wider(names_from = Statistic, values_from = value)

numeric_summary %>%
  gt() %>%
  tab_header(
    title = "Summary Statistics for Numerical Variables",
    subtitle = "Includes mean, median, minimum, and maximum values"
  ) %>%
  fmt_number(
    columns = c(Mean, Median, Minimum, Maximum),
    decimals = 2,
    use_seps = TRUE
  ) %>%
  tab_options(
    table.width = pct(100),
    data_row.padding = px(6)
  )
```

```{r}
#| echo: false
library(dplyr)
library(tidyr)
library(gt)

# Select categorical variables from your dataset
categorical_vars <- data %>%
  select(where(is.factor))

# Create summary table: top 5 most common values per categorical variable
cat_summary <- categorical_vars %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Value") %>%
  count(Variable, Value, sort = TRUE) %>%
  group_by(Variable) %>%
  slice_max(n, n = 5, with_ties = FALSE) %>%
  ungroup()

# Format and display with gt
cat_summary %>%
  gt() %>%
  tab_header(
    title = "Top Categories by Frequency",
    subtitle = "Most common values for each categorical variable"
  ) %>%
  cols_label(n = "Count") %>%
  tab_options(
    table.width = pct(100),
    data_row.padding = px(6)
  )

```


## Data Loading and Cleaning
*Merging Pollution and Demographic Data*
For this project, we worked with two datasets: `pollution_data.csv` and `demographic_data.csv`. Both datasets were read into R using the `read_csv()` function from the tidyverse package, and saved as `.rds` files using `write_rds()` for easier access later. The two datasets share some columns, including `Total Population`, `California County`, `CES 4.0 Score`, `CES 4.0 Percentile`, and `CES 4.0 Percentile Range`. So these columns were dropped from the `pollution_data` dataset before being merged with the `demographic_data` dataset. This was done using the following code:
```{r}
#| eval: false
#| code-overflow: wrap
pollution_data <- pollution_data |> 
    select(-c('Total Population', 'California County', 'CES 4.0 Score', 'CES 4.0 Percentile', 'CES 4.0 Percentile Range'))
```

The two datasets were then joined using a left join on the shared column "Census Tract" to ensure that all pollution records remained, even if corresponding demographic data was missing. This was done with the following line of code:
```{r}
#| eval: false
#| code-overflow: wrap
cleaned_dataset <- 
  left_join(pollution_data, demographic_data, by ="Census Tract")
```


*Removing Columns*

After merging, we removed several columns that were not relevant to our analysis. The original dataset included data for both air and water pollution. However, since our project is focused on air pollution we have removed the columns relevant to water pollution. These included environmental and social indicators such as drinking water, lead, pesticides, unemployment, and housing burden. Because the merge process introduced suffixes like .x and .y to distinguish duplicate column names, we used a for loop combined with select(-contains(...)) to remove all columns containing those key patterns, regardless of suffix:

```{r}
#| eval: false
#| code-overflow: wrap
columns_to_remove_patterns <- c(
"Drinking Water", "Lead", "Pesticides", "Groundwater Threats", "Imp. Water Bodies", "Education", "Linguistic Isolation","Poverty", "Unemployment", "Housing Burden"
)

for (pattern in columns_to_remove_patterns) {
  cleaned_dataset <- cleaned_dataset |>
    select(-contains(pattern))
}
```


*Imputing Missing Values*

We then checked for missing values using colSums(is.na(cleaned_dataset)) and found that several columns were missing data, particularly in Los Angeles. Despite this, we decided to impute any missing values using a k-nearest neighbors imputation method:
```{r}
#| eval: false
#| code-overflow: wrap
# convert character columns to factors 
cleaned_dataset <- cleaned_dataset |>
  mutate(across(where(is.character), as.factor))

# Impute any null values using KNN approach 
pollution_recipe <- recipe(~ ., data = cleaned_dataset) |>
  step_impute_knn(all_predictors(), , neighbors = 3)

prepared_recipe <- prep(pollution_recipe)

imputed_data <- bake(prepared_recipe, cleaned_dataset)
```


*Writing the Transformation to Cleaned Dataset*

Finally, the cleaned dataset was saved to an .rds file using:

```{r}
#| eval: false
#| code-overflow: wrap
write_rds(cleaned_dataset, file = here::here("dataset", "cleaned_dataset.rds"))
```

All steps were carried out using packages from the tidyverse, including dplyr and tidyr for data manipulation, readr for reading in the datasets, and gt for creating summary tables. We used the additional recipes package to use imputation to handle missing values using a KNN methodology. A full record of these operations is provided in the script: [clean_data.R](/scripts/clean_data.R).

Metrics on what data was missing in the original pollution dataset can be found in Blog Post 3.


